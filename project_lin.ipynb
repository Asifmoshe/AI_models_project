{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb45a3dd-8f53-43e3-b08d-31b82130e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression\n",
    "\n",
    "# LinearRegression\n",
    "# ---------- theory\n",
    "#\n",
    "# classification/regression/both ? regression\n",
    "#\n",
    "# what is the math problem here? i.e. find house price\n",
    "#   Answer: what are trying to find? trying to find the line equation (slope, intercept) with the min MSE\n",
    "#\n",
    "#   how to solve it in brute force --> try many lines (by changing slope + intercept over a large range) and keep the line\n",
    "#                                      with the best MSE\n",
    "#\n",
    "#   how is it solved by python (?) --> equation [line: closed formula (Normal Equation), plane: OLS Ordinary Least Squares (OLS)]\n",
    "# \n",
    "# evaluation (performance) - how to measure the success of the model?  R² (1-SSE/SST), MSE, adj R²\n",
    "#\n",
    "# 1 feature vrs. multi ? 1 feature == line , many features == plane\n",
    "# label = 2X + 1\n",
    "# label = 2X + 3Y + 2\n",
    "# label = 2X + 3Y + 150,000*Z + 5\n",
    "# label = w1X1 + w2X2 + w3X4 + .... wnXn + intercept\n",
    "#\n",
    "# ---------- practice:\n",
    "# how to run the model in python over a new observations (from code example): \n",
    "#    perpare data\n",
    "#    fit \n",
    "#    evaluation \n",
    "#    draw graph (?)\n",
    "#    predict over a new sample - X=103\n",
    "#    answer question (given a y find the x) -What is the X for Y=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3095bde-ee74-45a1-8054-a6782e7297b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "# classification/regression/both? \n",
    "#       answer: regression\n",
    "\n",
    "# what is the math problem here? \n",
    "#       answer: find the parabola which has the min MSE\n",
    "\n",
    "# how to solve it in brute force?\n",
    "#       answer: try many combinations of weights and intercepts to find min MSE and keep the weights and intercept for that MSE\n",
    "\n",
    "# how is it solved by python?\n",
    "#       answer: equation for line: Y = m*X + b\n",
    "#               equation for plane: Y = (X1*W1 + X2*W2+ ...) + b\n",
    "\n",
    "# what are the hyper-parameters of the model?\n",
    "#       answer: the hyper-parameter is the X_squared\n",
    "\n",
    "# how to drow the elbow of this model?\n",
    "#       answer: Y - MSE/(1-r2)\n",
    "#               X - power of X\n",
    "\n",
    "# 1 feature:\n",
    "# X = [...]\n",
    "# X = [1 X XX] power of 2\n",
    "# X = [1 X XX XXX] power of 3\n",
    "# multi:\n",
    "# X = [X1 X2]\n",
    "# X = [1 X1 X2 X1X1 X1X2 X2X2] power of 2\n",
    "\n",
    "# evaluation : measure r2/MSE/adj r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5a6056-9c3c-45c3-b44f-3550ee85b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression:\n",
    "# does the model solve a classification problem, a regression problem, or both?\n",
    "#        answer: classification\n",
    "\n",
    "# what is the shape of the output graph of a logistic regression model?\n",
    "#        answer: a sigmoid curve while X is the input features and Y is an output value between two numbers\n",
    "\n",
    "# what is the meaning of the value returned by the model before making the classification decision?\n",
    "#        answer: the value returned is a probability that the sample belongs to the positive class\n",
    "\n",
    "# which central mathematical function is used in logistic regression?\n",
    "#        answer: the sigmoid function : 1/(1 + e^-(WX + b))\n",
    "\n",
    "# how is the final decision about the class of a sample made?\n",
    "#        answer: the final decision is made by using a threshold if the sample's probability is equal or bigger than the threshold --> positive class\n",
    "#                else --> negetive class\n",
    "\n",
    "# what is a threshold and what is its role in the model?\n",
    "#        answer: the threshold is a line that choose if the sample is class 1 or 0 by seeing if the sample's probability is bigger than the threshold\n",
    "#               changing the threshold will change the behavior of the model\n",
    "\n",
    "# how does Python solve logistic regression – closed-form formula or mathematical approximation?\n",
    "#        answer: python uses gradient descent to mathematicly approximate the class \n",
    "\n",
    "# describe how a brute-force approach could find a formula that fits the data\n",
    "#        answer: try many combinations of weights and bias, calc cm/accuracy and choose the best parameters\n",
    "\n",
    "# is the threshold considered a hyperparameter? explain\n",
    "#        answer: yes, first;  it is not learned from the data\n",
    "#                     second; the user chooses it\n",
    "#                     third;  it efects the output of the model in each threshold\n",
    "\n",
    "# what is the fundamental difference between linear regression and logistic regression?\n",
    "#        answer: linear regression is for regression while logistic regression is for classification\n",
    "#                linear regression predicts continuous values while logistic predicts probabilities\n",
    "\n",
    "# which performance metrics are suitable for logistic regression?\n",
    "#        answer: accuracy and confusion matrix\n",
    "\n",
    "# what is a Confusion Matrix and what can we learn from it?\n",
    "#        answer: cm is a table that compares true labels with predict labels, it helps see how good is the model\n",
    "\n",
    "# can logistic regression be used with more than one feature? if yes, how does it affect the decision boundary?\n",
    "#        answer: yes, it will change the line to a plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b977e7bc-42ef-4691-882a-5e1358edf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# does the KNN algorithm solve a classification problem, a regression problem, or both?\n",
    "#        answer: it solves both classification and regression problems\n",
    "\n",
    "# what does the name KNN mean?\n",
    "#        answer: the name KNN represent K-Nearest Neighbors, K number of nearest points based on distance\n",
    "\n",
    "# what is the core idea behind the KNN algorithm?\n",
    "#        answer: close data points tend to have similar labels, the avg of those K points will be closest to the true label of the point\n",
    "\n",
    "# what is the role of the parameter K in KNN?\n",
    "#        answer: K determines how many neighbors are used to make the prediction, having a bigger K isn't allways a good choice\n",
    "\n",
    "# is K considered a hyperparameter? explain\n",
    "#        answer: yes; K is chosen by the user\n",
    "#                     changing K will affect the model performence\n",
    "#                     K isn't learned from the data\n",
    "\n",
    "# how does choosing a small value of K affect the model?\n",
    "#        answer: choosing a small K can cause an overfit because the prediction doesn't have much data to work with\n",
    "\n",
    "# how does choosing a large value of K affect the model?\n",
    "#        amswer: choosing a large K can give us smoother prediction and will use more data\n",
    "\n",
    "# what is an elbow graph?\n",
    "#        answer: elbow graph is a graph used to choose a good value of K by balancing the performance of the model(K vrs. MSE/accuracy)\n",
    "\n",
    "# how do we choose the sweet spot?\n",
    "#        answer: the spot can be selected the \"elbow\" of the graph, the point where the improvment starts to lower\n",
    "\n",
    "# give another model where an ELBOW graph is used\n",
    "#        answer: polynomial regression where K is sweeched with the degree of the polynomial in the graph\n",
    "\n",
    "# what is the difference between KNN for classification and KNN for regression?\n",
    "#        answer: the biggest diffrence between the 2 is that in regresion the model calc the avg of the K neighbors\n",
    "#                while in classification the model makes a vote between the K neighbors\n",
    "\n",
    "# how is the prediction made in KNN classification?\n",
    "#        answer: the model finds the K nearest neighbors and count their class labels, the class with most \"votes\" is the final label\n",
    "\n",
    "# how is the prediction made in KNN regression?\n",
    "#        answer: the model finds the K nearest neighbors and calc the avg of their values in order to find the final label \n",
    "\n",
    "# which distance metric is commonly used in KNN?\n",
    "#        answer: euclidean distance: d = sqrt(sum((x1-y1)^2))\n",
    "\n",
    "# how does the number of features affect KNN performance?\n",
    "#        answer: the more features --> the more dimensions, which often degrades the perforance of the model\n",
    "\n",
    "# is there a clear training phase in KNN?\n",
    "#        answer: no, each data point added to the model changes the model\n",
    "\n",
    "# how does python compute KNN – closed-form formula or direct computation at prediction time?\n",
    "#        answer: python uses direct computation at prediction time\n",
    "\n",
    "# what are the main advantages of KNN?\n",
    "#        answer: it is a simple and intuitive model\n",
    "#                works good with small data\n",
    "\n",
    "# what are the main disadvantages of KNN?\n",
    "#        answer: it has slow prediction time\n",
    "#                doesn't work well with multi-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abeed2d0-e801-4df0-8a70-72c0a5cb5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# does the SVM model solve a classification problem, a regression problem, or both?\n",
    "#        answer: it solves classification problems\n",
    "\n",
    "# what is the core idea behind the SVM model?\n",
    "#        answer: finding the separating boundary that maximizes the margin between classes\n",
    "\n",
    "# what is the margin in an SVM model?\n",
    "#        answer: the margin the distance between the 2 closest point of 2 classes\n",
    "\n",
    "# do the two margins have to be at equal distance from the separating hyperplane? explain\n",
    "#        answer: yes, this ensures a maximim and balanced seperation between classes\n",
    "\n",
    "# what are Support Vectors?\n",
    "#        answer: they are the closest points to the separating hyperplane, they lie on or inside the margin boundaries\n",
    "\n",
    "# can the SVM problem be solved using brute Force? if yes, describe the general idea.\n",
    "#        answer: yes, we try many hyperplanes, for each hyperplane we compute the margin and check if the classses are separated correctly\n",
    "#                     if we have more than 1 hyperplane that answers those conditions we choose the one with the largest margin\n",
    "\n",
    "# does SVM use a closed-form solution or mathematical approximation? explain\n",
    "#        answer: it uses mathematical approximation, if the sample is on A side of the margin --> class A\n",
    "#                                                                        B side of the margin --> class B\n",
    "\n",
    "# what are the main advantages of SVM?\n",
    "#        answer: it works well with high dimensional spaces\n",
    "#                effective with small or midium datasets\n",
    "\n",
    "# what are the main disadvantages of SVM?\n",
    "#        answer: #########################################\n",
    "\n",
    "# if we wish to train-test split, explain the process\n",
    "#        answer: first we split our data to train groop and test groop, we train the model with the train groop and after training we evaluate \n",
    "#                performance on the test groop\n",
    "# why we should use train-test split?\n",
    "#        answer: we should use it so we could prevent overfitting, we can see how the model works live with unseen data\n",
    "\n",
    "# which performance metrics are suitable for evaluating an SVM classification model?\n",
    "#        answer: accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e569a0e-0659-4b71-ab7a-a9ce391c5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "# does a decision tree model solve a classification problem, a regression problem, or both?\n",
    "#        answer: it solves both classification and regression problems\n",
    "\n",
    "# what is the core idea behind the decision tree model?\n",
    "#        answer: splitting the data into small groops using decision rules, each rule cuts the data more\n",
    "\n",
    "# what is gini impurity?\n",
    "#        answer: it represents the probability that the predictions are incorrect according to the class distribution on the graph\n",
    "\n",
    "# how does gini impurity measure the quality of a split?\n",
    "#        answer: it checks for the split that gives the lowest gini impurity, it checks the gini gain from the node before\n",
    "\n",
    "# what is the value of gini impurity when a node is completely pure?\n",
    "#        answer: the gini will be 0 because the equation for gini impurity is: 1 - sum((class_proportion)^2), so it will be: 1 - 1^2\n",
    "\n",
    "# what is the goal of splitting at each node?\n",
    "#        answer: tring to find nodes as pure as possible and minimizing errors\n",
    "\n",
    "# explain the splitting mechanism in a regression tree\n",
    "#        answer: the spilts are tring to minimize the MSE, each split reduce the MSE\n",
    "\n",
    "# when we reach the bottom of the tree, how is the prediction computed from the leaf nodes?\n",
    "#        answer: regression: we take the avg of the target values in the leaf \n",
    "#                classification: we take the class that has the majority, if all equal then we choose the class who appear first\n",
    "\n",
    "# what common hyperparameters exist in decision trees?\n",
    "#        answer: max depth/ min leaf nodes\n",
    "\n",
    "# how does tree depth affect overfitting and underfitting?\n",
    "#        what happens when the tree is very deep?\n",
    "#              answer: the deeper the tree --> the higher the chance for overfit\n",
    "#        what happens when the tree is very shallow?\n",
    "#              answer: the shallower the tree --> the higher the chance for underfit\n",
    "\n",
    "# which performance metrics are suitable for evaluating a decision tree?\n",
    "#        answer: regression: MSE/r2\n",
    "#                classification: accuracy/CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08da8ea0-6a50-4bef-b52f-77edff717ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "# does the random forest model solve a classification problem, a regression problem, or both?\n",
    "#        answer: it solves both classification and regression problems\n",
    "\n",
    "# what is the core idea behind the random forest model?\n",
    "#        answer: creating many decision trees using some of the data in each tree and agregate their predictions to get better accuracy\n",
    "\n",
    "# how is random forest related to the decision tree model?\n",
    "#        answer: random forest is made of many decision trees\n",
    " \n",
    "# what is bootstrap sampling and how is it used in random forest?\n",
    "#        answer: a bootstrap sampling is sampling the training data with replacement(some samples appear multiple times and some dont appear at all)\n",
    "\n",
    "# why does using randomness improve model performance?\n",
    "#        answer: it prevents all trees from making the same mistakes\n",
    "#                each tree will have diffrent features\n",
    "\n",
    "# how is the final prediction made in random forest for classification?\n",
    "#        answer: the final prediction is made with every tree predict a class and the majority vote from all trees is the final class\n",
    "\n",
    "# what is the voting mechanism in random forest and how does it work?\n",
    "#        answer: each tree vote for a class using his conditions, the class with most votes is the final prediction\n",
    "\n",
    "# how is the final prediction made in random forest for regression?\n",
    "#        answer: each tree predict a number using his conditions, the model calc the avg of all values and returns the final prediction\n",
    "\n",
    "# what common hyperparameters exist in the random forest model?\n",
    "#        answer: number of trees\n",
    "#                max depth\n",
    "#                min samples leaf\n",
    "\n",
    "# what is OOB error (out-of-bag error) and how is it used?\n",
    "#        answer: OOB samples are data points not included in a tree’s bootstrap sample\n",
    "#                each tree predicts its OOB samples\n",
    "#                aggregating these predictions gives the OOB error estimate#\n",
    "\n",
    "# what is the advantage of random forest in terms of model stability compared to a decision tree?\n",
    "#        answer: random forest is far nore stable since he uses the avg of many trees\n",
    "\n",
    "# which performance metrics are suitable for evaluating a random forest model?\n",
    "#        answer: regrwssion: MSE\n",
    "#                            R2\n",
    "#                classification: accuracy\n",
    "#                                CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d64f1e-4291-4099-832e-7b5d9e3ec223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
